//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	computeDepthMap
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry computeDepthMap(
	.param .u32 computeDepthMap_param_0,
	.param .u32 computeDepthMap_param_1,
	.param .f32 computeDepthMap_param_2,
	.param .f32 computeDepthMap_param_3,
	.param .f32 computeDepthMap_param_4,
	.param .f32 computeDepthMap_param_5,
	.param .f32 computeDepthMap_param_6,
	.param .f32 computeDepthMap_param_7,
	.param .u64 computeDepthMap_param_8
)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<176>;
	.reg .b32 	%r<273>;
	.reg .f64 	%fd<14>;
	.reg .b64 	%rd<103>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u32 	%r93, [computeDepthMap_param_0];
	ld.param.u32 	%r94, [computeDepthMap_param_1];
	ld.param.f32 	%f57, [computeDepthMap_param_2];
	ld.param.f32 	%f58, [computeDepthMap_param_3];
	ld.param.f32 	%f59, [computeDepthMap_param_4];
	ld.param.f32 	%f60, [computeDepthMap_param_5];
	ld.param.f32 	%f61, [computeDepthMap_param_6];
	ld.param.f32 	%f62, [computeDepthMap_param_7];
	ld.param.u64 	%rd33, [computeDepthMap_param_8];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r95, %ntid.x;
	mov.u32 	%r96, %ctaid.x;
	mov.u32 	%r97, %tid.x;
	mad.lo.s32 	%r1, %r96, %r95, %r97;
	mov.u32 	%r98, %ntid.y;
	mov.u32 	%r99, %ctaid.y;
	mov.u32 	%r100, %tid.y;
	mad.lo.s32 	%r2, %r99, %r98, %r100;
	setp.ge.s32 	%p1, %r1, %r93;
	setp.ge.s32 	%p2, %r2, %r94;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_62;

	mul.f32 	%f63, %f61, 0f3F22F983;
	cvt.rni.s32.f32 	%r272, %f63;
	cvt.rn.f32.s32 	%f64, %r272;
	mov.f32 	%f65, 0fBFC90FDA;
	fma.rn.f32 	%f66, %f64, %f65, %f61;
	mov.f32 	%f67, 0fB3A22168;
	fma.rn.f32 	%f68, %f64, %f67, %f66;
	mov.f32 	%f69, 0fA7C234C5;
	fma.rn.f32 	%f173, %f64, %f69, %f68;
	abs.f32 	%f2, %f61;
	setp.ltu.f32 	%p4, %f2, 0f47CE4780;
	add.s64 	%rd2, %rd1, 24;
	mov.u32 	%r256, %r272;
	mov.f32 	%f161, %f173;
	@%p4 bra 	$L__BB0_9;

	setp.eq.f32 	%p5, %f2, 0f7F800000;
	@%p5 bra 	$L__BB0_8;
	bra.uni 	$L__BB0_3;

$L__BB0_8:
	mov.f32 	%f72, 0f00000000;
	mul.rn.f32 	%f161, %f61, %f72;
	mov.u32 	%r256, 0;
	bra.uni 	$L__BB0_9;

$L__BB0_3:
	mov.b32 	%r4, %f61;
	bfe.u32 	%r102, %r4, 23, 8;
	add.s32 	%r5, %r102, -128;
	shl.b32 	%r103, %r4, 8;
	or.b32  	%r6, %r103, -2147483648;
	shr.u32 	%r7, %r5, 5;
	mov.u64 	%rd90, 0;
	mov.u32 	%r253, 0;
	mov.u64 	%rd89, __cudart_i2opi_f;
	mov.u64 	%rd88, %rd1;

$L__BB0_4:
	.pragma "nounroll";
	ld.global.nc.u32 	%r104, [%rd89];
	mad.wide.u32 	%rd37, %r104, %r6, %rd90;
	shr.u64 	%rd90, %rd37, 32;
	st.local.u32 	[%rd88], %rd37;
	add.s64 	%rd89, %rd89, 4;
	add.s64 	%rd88, %rd88, 4;
	add.s32 	%r253, %r253, 1;
	setp.ne.s32 	%p6, %r253, 6;
	@%p6 bra 	$L__BB0_4;

	st.local.u32 	[%rd2], %rd90;
	mov.u32 	%r105, 4;
	sub.s32 	%r10, %r105, %r7;
	mov.u32 	%r106, 6;
	sub.s32 	%r107, %r106, %r7;
	mul.wide.s32 	%rd38, %r107, 4;
	add.s64 	%rd39, %rd1, %rd38;
	ld.local.u32 	%r254, [%rd39];
	ld.local.u32 	%r255, [%rd39+-4];
	and.b32  	%r13, %r5, 31;
	setp.eq.s32 	%p7, %r13, 0;
	@%p7 bra 	$L__BB0_7;

	mov.u32 	%r108, 32;
	sub.s32 	%r109, %r108, %r13;
	shr.u32 	%r110, %r255, %r109;
	shl.b32 	%r111, %r254, %r13;
	add.s32 	%r254, %r110, %r111;
	mul.wide.s32 	%rd40, %r10, 4;
	add.s64 	%rd41, %rd1, %rd40;
	ld.local.u32 	%r112, [%rd41];
	shr.u32 	%r113, %r112, %r109;
	shl.b32 	%r114, %r255, %r13;
	add.s32 	%r255, %r113, %r114;

$L__BB0_7:
	and.b32  	%r115, %r4, -2147483648;
	shr.u32 	%r116, %r255, 30;
	shl.b32 	%r117, %r254, 2;
	or.b32  	%r118, %r116, %r117;
	shr.u32 	%r119, %r118, 31;
	shr.u32 	%r120, %r254, 30;
	add.s32 	%r121, %r119, %r120;
	neg.s32 	%r122, %r121;
	setp.eq.s32 	%p8, %r115, 0;
	selp.b32 	%r256, %r121, %r122, %p8;
	setp.ne.s32 	%p9, %r119, 0;
	xor.b32  	%r123, %r115, -2147483648;
	selp.b32 	%r124, %r123, %r115, %p9;
	selp.b32 	%r125, -1, 0, %p9;
	xor.b32  	%r126, %r118, %r125;
	shl.b32 	%r127, %r255, 2;
	xor.b32  	%r128, %r127, %r125;
	cvt.u64.u32 	%rd42, %r126;
	cvt.u64.u32 	%rd43, %r128;
	bfi.b64 	%rd44, %rd42, %rd43, 32, 32;
	cvt.rn.f64.s64 	%fd1, %rd44;
	mul.f64 	%fd2, %fd1, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f70, %fd2;
	setp.eq.s32 	%p10, %r124, 0;
	neg.f32 	%f71, %f70;
	selp.f32 	%f161, %f70, %f71, %p10;

$L__BB0_9:
	and.b32  	%r20, %r256, 1;
	setp.eq.s32 	%p11, %r20, 0;
	selp.f32 	%f6, %f161, 0f3F800000, %p11;
	mul.rn.f32 	%f7, %f161, %f161;
	mov.f32 	%f162, 0fB94D4153;
	@%p11 bra 	$L__BB0_11;

	mov.f32 	%f74, 0fBAB607ED;
	mov.f32 	%f75, 0f37CBAC00;
	fma.rn.f32 	%f162, %f75, %f7, %f74;

$L__BB0_11:
	selp.f32 	%f76, 0f3C0885E4, 0f3D2AAABB, %p11;
	fma.rn.f32 	%f77, %f162, %f7, %f76;
	selp.f32 	%f78, 0fBE2AAAA8, 0fBEFFFFFF, %p11;
	fma.rn.f32 	%f79, %f77, %f7, %f78;
	mov.f32 	%f80, 0f00000000;
	fma.rn.f32 	%f81, %f7, %f6, %f80;
	fma.rn.f32 	%f163, %f79, %f81, %f6;
	and.b32  	%r130, %r256, 2;
	setp.eq.s32 	%p13, %r130, 0;
	@%p13 bra 	$L__BB0_13;

	mov.f32 	%f83, 0fBF800000;
	fma.rn.f32 	%f163, %f163, %f83, %f80;

$L__BB0_13:
	mul.f32 	%f84, %f62, 0f3F22F983;
	cvt.rni.s32.f32 	%r268, %f84;
	cvt.rn.f32.s32 	%f85, %r268;
	mov.f32 	%f86, 0fBFC90FDA;
	fma.rn.f32 	%f87, %f85, %f86, %f62;
	mov.f32 	%f88, 0fB3A22168;
	fma.rn.f32 	%f89, %f85, %f88, %f87;
	mov.f32 	%f90, 0fA7C234C5;
	fma.rn.f32 	%f170, %f85, %f90, %f89;
	abs.f32 	%f14, %f62;
	setp.ltu.f32 	%p14, %f14, 0f47CE4780;
	mov.u32 	%r260, %r268;
	mov.f32 	%f164, %f170;
	@%p14 bra 	$L__BB0_21;

	setp.eq.f32 	%p15, %f14, 0f7F800000;
	@%p15 bra 	$L__BB0_20;
	bra.uni 	$L__BB0_15;

$L__BB0_20:
	mov.f32 	%f93, 0f00000000;
	mul.rn.f32 	%f164, %f62, %f93;
	mov.u32 	%r260, 0;
	bra.uni 	$L__BB0_21;

$L__BB0_15:
	mov.b32 	%r22, %f62;
	bfe.u32 	%r132, %r22, 23, 8;
	add.s32 	%r23, %r132, -128;
	shl.b32 	%r133, %r22, 8;
	or.b32  	%r24, %r133, -2147483648;
	shr.u32 	%r25, %r23, 5;
	mov.u64 	%rd93, 0;
	mov.u32 	%r257, 0;
	mov.u64 	%rd92, __cudart_i2opi_f;
	mov.u64 	%rd91, %rd1;

$L__BB0_16:
	.pragma "nounroll";
	ld.global.nc.u32 	%r134, [%rd92];
	mad.wide.u32 	%rd47, %r134, %r24, %rd93;
	shr.u64 	%rd93, %rd47, 32;
	st.local.u32 	[%rd91], %rd47;
	add.s64 	%rd92, %rd92, 4;
	add.s64 	%rd91, %rd91, 4;
	add.s32 	%r257, %r257, 1;
	setp.ne.s32 	%p16, %r257, 6;
	@%p16 bra 	$L__BB0_16;

	st.local.u32 	[%rd2], %rd93;
	mov.u32 	%r135, 4;
	sub.s32 	%r28, %r135, %r25;
	mov.u32 	%r136, 6;
	sub.s32 	%r137, %r136, %r25;
	mul.wide.s32 	%rd48, %r137, 4;
	add.s64 	%rd49, %rd1, %rd48;
	ld.local.u32 	%r258, [%rd49];
	ld.local.u32 	%r259, [%rd49+-4];
	and.b32  	%r31, %r23, 31;
	setp.eq.s32 	%p17, %r31, 0;
	@%p17 bra 	$L__BB0_19;

	mov.u32 	%r138, 32;
	sub.s32 	%r139, %r138, %r31;
	shr.u32 	%r140, %r259, %r139;
	shl.b32 	%r141, %r258, %r31;
	add.s32 	%r258, %r140, %r141;
	mul.wide.s32 	%rd50, %r28, 4;
	add.s64 	%rd51, %rd1, %rd50;
	ld.local.u32 	%r142, [%rd51];
	shr.u32 	%r143, %r142, %r139;
	shl.b32 	%r144, %r259, %r31;
	add.s32 	%r259, %r143, %r144;

$L__BB0_19:
	and.b32  	%r145, %r22, -2147483648;
	shr.u32 	%r146, %r259, 30;
	shl.b32 	%r147, %r258, 2;
	or.b32  	%r148, %r146, %r147;
	shr.u32 	%r149, %r148, 31;
	shr.u32 	%r150, %r258, 30;
	add.s32 	%r151, %r149, %r150;
	neg.s32 	%r152, %r151;
	setp.eq.s32 	%p18, %r145, 0;
	selp.b32 	%r260, %r151, %r152, %p18;
	setp.ne.s32 	%p19, %r149, 0;
	xor.b32  	%r153, %r145, -2147483648;
	selp.b32 	%r154, %r153, %r145, %p19;
	selp.b32 	%r155, -1, 0, %p19;
	xor.b32  	%r156, %r148, %r155;
	shl.b32 	%r157, %r259, 2;
	xor.b32  	%r158, %r157, %r155;
	cvt.u64.u32 	%rd52, %r156;
	cvt.u64.u32 	%rd53, %r158;
	bfi.b64 	%rd54, %rd52, %rd53, 32, 32;
	cvt.rn.f64.s64 	%fd3, %rd54;
	mul.f64 	%fd4, %fd3, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f91, %fd4;
	setp.eq.s32 	%p20, %r154, 0;
	neg.f32 	%f92, %f91;
	selp.f32 	%f164, %f91, %f92, %p20;

$L__BB0_21:
	add.s32 	%r38, %r260, 1;
	and.b32  	%r39, %r38, 1;
	setp.eq.s32 	%p21, %r39, 0;
	selp.f32 	%f18, %f164, 0f3F800000, %p21;
	mul.rn.f32 	%f19, %f164, %f164;
	mov.f32 	%f165, 0fB94D4153;
	@%p21 bra 	$L__BB0_23;

	mov.f32 	%f95, 0fBAB607ED;
	mov.f32 	%f96, 0f37CBAC00;
	fma.rn.f32 	%f165, %f96, %f19, %f95;

$L__BB0_23:
	selp.f32 	%f97, 0f3C0885E4, 0f3D2AAABB, %p21;
	fma.rn.f32 	%f98, %f165, %f19, %f97;
	selp.f32 	%f99, 0fBE2AAAA8, 0fBEFFFFFF, %p21;
	fma.rn.f32 	%f100, %f98, %f19, %f99;
	mov.f32 	%f101, 0f00000000;
	fma.rn.f32 	%f102, %f19, %f18, %f101;
	fma.rn.f32 	%f166, %f100, %f102, %f18;
	and.b32  	%r160, %r38, 2;
	setp.eq.s32 	%p23, %r160, 0;
	@%p23 bra 	$L__BB0_25;

	mov.f32 	%f104, 0fBF800000;
	fma.rn.f32 	%f166, %f166, %f104, %f101;

$L__BB0_25:
	cvt.rn.f32.s32 	%f105, %r93;
	cvt.rn.f32.s32 	%f106, %r1;
	fma.rn.f32 	%f107, %f105, 0fBF000000, %f106;
	fma.rn.f32 	%f25, %f163, %f166, %f107;
	mov.u32 	%r264, %r272;
	mov.f32 	%f167, %f173;
	@%p4 bra 	$L__BB0_33;

	setp.eq.f32 	%p25, %f2, 0f7F800000;
	@%p25 bra 	$L__BB0_32;
	bra.uni 	$L__BB0_27;

$L__BB0_32:
	mov.f32 	%f110, 0f00000000;
	mul.rn.f32 	%f167, %f61, %f110;
	mov.u32 	%r264, 0;
	bra.uni 	$L__BB0_33;

$L__BB0_27:
	mov.b32 	%r40, %f61;
	bfe.u32 	%r162, %r40, 23, 8;
	add.s32 	%r41, %r162, -128;
	shl.b32 	%r163, %r40, 8;
	or.b32  	%r42, %r163, -2147483648;
	shr.u32 	%r43, %r41, 5;
	mov.u64 	%rd96, 0;
	mov.u32 	%r261, 0;
	mov.u64 	%rd95, __cudart_i2opi_f;
	mov.u64 	%rd94, %rd1;

$L__BB0_28:
	.pragma "nounroll";
	ld.global.nc.u32 	%r164, [%rd95];
	mad.wide.u32 	%rd57, %r164, %r42, %rd96;
	shr.u64 	%rd96, %rd57, 32;
	st.local.u32 	[%rd94], %rd57;
	add.s64 	%rd95, %rd95, 4;
	add.s64 	%rd94, %rd94, 4;
	add.s32 	%r261, %r261, 1;
	setp.ne.s32 	%p26, %r261, 6;
	@%p26 bra 	$L__BB0_28;

	st.local.u32 	[%rd2], %rd96;
	mov.u32 	%r165, 4;
	sub.s32 	%r46, %r165, %r43;
	mov.u32 	%r166, 6;
	sub.s32 	%r167, %r166, %r43;
	mul.wide.s32 	%rd58, %r167, 4;
	add.s64 	%rd59, %rd1, %rd58;
	ld.local.u32 	%r262, [%rd59];
	ld.local.u32 	%r263, [%rd59+-4];
	and.b32  	%r49, %r41, 31;
	setp.eq.s32 	%p27, %r49, 0;
	@%p27 bra 	$L__BB0_31;

	mov.u32 	%r168, 32;
	sub.s32 	%r169, %r168, %r49;
	shr.u32 	%r170, %r263, %r169;
	shl.b32 	%r171, %r262, %r49;
	add.s32 	%r262, %r170, %r171;
	mul.wide.s32 	%rd60, %r46, 4;
	add.s64 	%rd61, %rd1, %rd60;
	ld.local.u32 	%r172, [%rd61];
	shr.u32 	%r173, %r172, %r169;
	shl.b32 	%r174, %r263, %r49;
	add.s32 	%r263, %r173, %r174;

$L__BB0_31:
	and.b32  	%r175, %r40, -2147483648;
	shr.u32 	%r176, %r263, 30;
	shl.b32 	%r177, %r262, 2;
	or.b32  	%r178, %r176, %r177;
	shr.u32 	%r179, %r178, 31;
	shr.u32 	%r180, %r262, 30;
	add.s32 	%r181, %r179, %r180;
	neg.s32 	%r182, %r181;
	setp.eq.s32 	%p28, %r175, 0;
	selp.b32 	%r264, %r181, %r182, %p28;
	setp.ne.s32 	%p29, %r179, 0;
	xor.b32  	%r183, %r175, -2147483648;
	selp.b32 	%r184, %r183, %r175, %p29;
	selp.b32 	%r185, -1, 0, %p29;
	xor.b32  	%r186, %r178, %r185;
	shl.b32 	%r187, %r263, 2;
	xor.b32  	%r188, %r187, %r185;
	cvt.u64.u32 	%rd62, %r186;
	cvt.u64.u32 	%rd63, %r188;
	bfi.b64 	%rd64, %rd62, %rd63, 32, 32;
	cvt.rn.f64.s64 	%fd5, %rd64;
	mul.f64 	%fd6, %fd5, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f108, %fd6;
	setp.eq.s32 	%p30, %r184, 0;
	neg.f32 	%f109, %f108;
	selp.f32 	%f167, %f108, %f109, %p30;

$L__BB0_33:
	and.b32  	%r56, %r264, 1;
	setp.eq.s32 	%p31, %r56, 0;
	selp.f32 	%f29, %f167, 0f3F800000, %p31;
	mul.rn.f32 	%f30, %f167, %f167;
	mov.f32 	%f168, 0fB94D4153;
	@%p31 bra 	$L__BB0_35;

	mov.f32 	%f112, 0fBAB607ED;
	mov.f32 	%f113, 0f37CBAC00;
	fma.rn.f32 	%f168, %f113, %f30, %f112;

$L__BB0_35:
	selp.f32 	%f114, 0f3C0885E4, 0f3D2AAABB, %p31;
	fma.rn.f32 	%f115, %f168, %f30, %f114;
	selp.f32 	%f116, 0fBE2AAAA8, 0fBEFFFFFF, %p31;
	fma.rn.f32 	%f117, %f115, %f30, %f116;
	mov.f32 	%f118, 0f00000000;
	fma.rn.f32 	%f119, %f30, %f29, %f118;
	fma.rn.f32 	%f169, %f117, %f119, %f29;
	and.b32  	%r190, %r264, 2;
	setp.eq.s32 	%p33, %r190, 0;
	@%p33 bra 	$L__BB0_37;

	mov.f32 	%f121, 0fBF800000;
	fma.rn.f32 	%f169, %f169, %f121, %f118;

$L__BB0_37:
	@%p14 bra 	$L__BB0_45;

	setp.eq.f32 	%p35, %f14, 0f7F800000;
	@%p35 bra 	$L__BB0_44;
	bra.uni 	$L__BB0_39;

$L__BB0_44:
	mov.f32 	%f124, 0f00000000;
	mul.rn.f32 	%f170, %f62, %f124;
	mov.u32 	%r268, 0;
	bra.uni 	$L__BB0_45;

$L__BB0_39:
	mov.b32 	%r57, %f62;
	bfe.u32 	%r192, %r57, 23, 8;
	add.s32 	%r58, %r192, -128;
	shl.b32 	%r193, %r57, 8;
	or.b32  	%r59, %r193, -2147483648;
	shr.u32 	%r60, %r58, 5;
	mov.u64 	%rd99, 0;
	mov.u32 	%r265, 0;
	mov.u64 	%rd98, __cudart_i2opi_f;
	mov.u64 	%rd97, %rd1;

$L__BB0_40:
	.pragma "nounroll";
	ld.global.nc.u32 	%r194, [%rd98];
	mad.wide.u32 	%rd67, %r194, %r59, %rd99;
	shr.u64 	%rd99, %rd67, 32;
	st.local.u32 	[%rd97], %rd67;
	add.s64 	%rd98, %rd98, 4;
	add.s64 	%rd97, %rd97, 4;
	add.s32 	%r265, %r265, 1;
	setp.ne.s32 	%p36, %r265, 6;
	@%p36 bra 	$L__BB0_40;

	st.local.u32 	[%rd2], %rd99;
	mov.u32 	%r195, 4;
	sub.s32 	%r63, %r195, %r60;
	mov.u32 	%r196, 6;
	sub.s32 	%r197, %r196, %r60;
	mul.wide.s32 	%rd68, %r197, 4;
	add.s64 	%rd69, %rd1, %rd68;
	ld.local.u32 	%r266, [%rd69];
	ld.local.u32 	%r267, [%rd69+-4];
	and.b32  	%r66, %r58, 31;
	setp.eq.s32 	%p37, %r66, 0;
	@%p37 bra 	$L__BB0_43;

	mov.u32 	%r198, 32;
	sub.s32 	%r199, %r198, %r66;
	shr.u32 	%r200, %r267, %r199;
	shl.b32 	%r201, %r266, %r66;
	add.s32 	%r266, %r200, %r201;
	mul.wide.s32 	%rd70, %r63, 4;
	add.s64 	%rd71, %rd1, %rd70;
	ld.local.u32 	%r202, [%rd71];
	shr.u32 	%r203, %r202, %r199;
	shl.b32 	%r204, %r267, %r66;
	add.s32 	%r267, %r203, %r204;

$L__BB0_43:
	and.b32  	%r205, %r57, -2147483648;
	shr.u32 	%r206, %r267, 30;
	shl.b32 	%r207, %r266, 2;
	or.b32  	%r208, %r206, %r207;
	shr.u32 	%r209, %r208, 31;
	shr.u32 	%r210, %r266, 30;
	add.s32 	%r211, %r209, %r210;
	neg.s32 	%r212, %r211;
	setp.eq.s32 	%p38, %r205, 0;
	selp.b32 	%r268, %r211, %r212, %p38;
	setp.ne.s32 	%p39, %r209, 0;
	xor.b32  	%r213, %r205, -2147483648;
	selp.b32 	%r214, %r213, %r205, %p39;
	selp.b32 	%r215, -1, 0, %p39;
	xor.b32  	%r216, %r208, %r215;
	shl.b32 	%r217, %r267, 2;
	xor.b32  	%r218, %r217, %r215;
	cvt.u64.u32 	%rd72, %r216;
	cvt.u64.u32 	%rd73, %r218;
	bfi.b64 	%rd74, %rd72, %rd73, 32, 32;
	cvt.rn.f64.s64 	%fd7, %rd74;
	mul.f64 	%fd8, %fd7, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f122, %fd8;
	setp.eq.s32 	%p40, %r214, 0;
	neg.f32 	%f123, %f122;
	selp.f32 	%f170, %f122, %f123, %p40;

$L__BB0_45:
	and.b32  	%r73, %r268, 1;
	setp.eq.s32 	%p41, %r73, 0;
	selp.f32 	%f39, %f170, 0f3F800000, %p41;
	mul.rn.f32 	%f40, %f170, %f170;
	mov.f32 	%f171, 0fB94D4153;
	@%p41 bra 	$L__BB0_47;

	mov.f32 	%f126, 0fBAB607ED;
	mov.f32 	%f127, 0f37CBAC00;
	fma.rn.f32 	%f171, %f127, %f40, %f126;

$L__BB0_47:
	selp.f32 	%f128, 0f3C0885E4, 0f3D2AAABB, %p41;
	fma.rn.f32 	%f129, %f171, %f40, %f128;
	selp.f32 	%f130, 0fBE2AAAA8, 0fBEFFFFFF, %p41;
	fma.rn.f32 	%f131, %f129, %f40, %f130;
	mov.f32 	%f132, 0f00000000;
	fma.rn.f32 	%f133, %f40, %f39, %f132;
	fma.rn.f32 	%f172, %f131, %f133, %f39;
	and.b32  	%r220, %r268, 2;
	setp.eq.s32 	%p43, %r220, 0;
	@%p43 bra 	$L__BB0_49;

	mov.f32 	%f135, 0fBF800000;
	fma.rn.f32 	%f172, %f172, %f135, %f132;

$L__BB0_49:
	cvt.rn.f32.s32 	%f136, %r94;
	cvt.rn.f32.s32 	%f137, %r2;
	fma.rn.f32 	%f138, %f136, 0fBF000000, %f137;
	fma.rn.f32 	%f46, %f169, %f172, %f138;
	mad.lo.s32 	%r74, %r2, %r93, %r1;
	@%p4 bra 	$L__BB0_57;

	setp.eq.f32 	%p45, %f2, 0f7F800000;
	@%p45 bra 	$L__BB0_56;
	bra.uni 	$L__BB0_51;

$L__BB0_56:
	mov.f32 	%f141, 0f00000000;
	mul.rn.f32 	%f173, %f61, %f141;
	mov.u32 	%r272, 0;
	bra.uni 	$L__BB0_57;

$L__BB0_51:
	mov.b32 	%r75, %f61;
	bfe.u32 	%r222, %r75, 23, 8;
	add.s32 	%r76, %r222, -128;
	shl.b32 	%r223, %r75, 8;
	or.b32  	%r77, %r223, -2147483648;
	shr.u32 	%r78, %r76, 5;
	mov.u64 	%rd102, 0;
	mov.u32 	%r269, 0;
	mov.u64 	%rd101, __cudart_i2opi_f;
	mov.u64 	%rd100, %rd1;

$L__BB0_52:
	.pragma "nounroll";
	ld.global.nc.u32 	%r224, [%rd101];
	mad.wide.u32 	%rd77, %r224, %r77, %rd102;
	shr.u64 	%rd102, %rd77, 32;
	st.local.u32 	[%rd100], %rd77;
	add.s64 	%rd101, %rd101, 4;
	add.s64 	%rd100, %rd100, 4;
	add.s32 	%r269, %r269, 1;
	setp.ne.s32 	%p46, %r269, 6;
	@%p46 bra 	$L__BB0_52;

	st.local.u32 	[%rd2], %rd102;
	mov.u32 	%r225, 4;
	sub.s32 	%r81, %r225, %r78;
	mov.u32 	%r226, 6;
	sub.s32 	%r227, %r226, %r78;
	mul.wide.s32 	%rd78, %r227, 4;
	add.s64 	%rd79, %rd1, %rd78;
	ld.local.u32 	%r270, [%rd79];
	ld.local.u32 	%r271, [%rd79+-4];
	and.b32  	%r84, %r76, 31;
	setp.eq.s32 	%p47, %r84, 0;
	@%p47 bra 	$L__BB0_55;

	mov.u32 	%r228, 32;
	sub.s32 	%r229, %r228, %r84;
	shr.u32 	%r230, %r271, %r229;
	shl.b32 	%r231, %r270, %r84;
	add.s32 	%r270, %r230, %r231;
	mul.wide.s32 	%rd80, %r81, 4;
	add.s64 	%rd81, %rd1, %rd80;
	ld.local.u32 	%r232, [%rd81];
	shr.u32 	%r233, %r232, %r229;
	shl.b32 	%r234, %r271, %r84;
	add.s32 	%r271, %r233, %r234;

$L__BB0_55:
	and.b32  	%r235, %r75, -2147483648;
	shr.u32 	%r236, %r271, 30;
	shl.b32 	%r237, %r270, 2;
	or.b32  	%r238, %r236, %r237;
	shr.u32 	%r239, %r238, 31;
	shr.u32 	%r240, %r270, 30;
	add.s32 	%r241, %r239, %r240;
	neg.s32 	%r242, %r241;
	setp.eq.s32 	%p48, %r235, 0;
	selp.b32 	%r272, %r241, %r242, %p48;
	setp.ne.s32 	%p49, %r239, 0;
	xor.b32  	%r243, %r235, -2147483648;
	selp.b32 	%r244, %r243, %r235, %p49;
	selp.b32 	%r245, -1, 0, %p49;
	xor.b32  	%r246, %r238, %r245;
	shl.b32 	%r247, %r271, 2;
	xor.b32  	%r248, %r247, %r245;
	cvt.u64.u32 	%rd82, %r246;
	cvt.u64.u32 	%rd83, %r248;
	bfi.b64 	%rd84, %rd82, %rd83, 32, 32;
	cvt.rn.f64.s64 	%fd9, %rd84;
	mul.f64 	%fd10, %fd9, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f139, %fd10;
	setp.eq.s32 	%p50, %r244, 0;
	neg.f32 	%f140, %f139;
	selp.f32 	%f173, %f139, %f140, %p50;

$L__BB0_57:
	add.s32 	%r91, %r272, 1;
	and.b32  	%r92, %r91, 1;
	setp.eq.s32 	%p51, %r92, 0;
	selp.f32 	%f50, %f173, 0f3F800000, %p51;
	mul.rn.f32 	%f51, %f173, %f173;
	mov.f32 	%f174, 0fB94D4153;
	@%p51 bra 	$L__BB0_59;

	mov.f32 	%f143, 0fBAB607ED;
	mov.f32 	%f144, 0f37CBAC00;
	fma.rn.f32 	%f174, %f144, %f51, %f143;

$L__BB0_59:
	selp.f32 	%f145, 0f3C0885E4, 0f3D2AAABB, %p51;
	fma.rn.f32 	%f146, %f174, %f51, %f145;
	selp.f32 	%f147, 0fBE2AAAA8, 0fBEFFFFFF, %p51;
	fma.rn.f32 	%f148, %f146, %f51, %f147;
	mov.f32 	%f149, 0f00000000;
	fma.rn.f32 	%f150, %f51, %f50, %f149;
	fma.rn.f32 	%f175, %f148, %f150, %f50;
	and.b32  	%r250, %r91, 2;
	setp.eq.s32 	%p53, %r250, 0;
	@%p53 bra 	$L__BB0_61;

	mov.f32 	%f152, 0fBF800000;
	fma.rn.f32 	%f175, %f175, %f152, %f149;

$L__BB0_61:
	sub.f32 	%f153, %f25, %f57;
	sub.f32 	%f154, %f46, %f58;
	mul.f32 	%f155, %f154, %f154;
	fma.rn.f32 	%f156, %f153, %f153, %f155;
	sub.f32 	%f157, %f175, %f59;
	fma.rn.f32 	%f158, %f157, %f157, %f156;
	sqrt.rn.f32 	%f159, %f158;
	sub.f32 	%f160, %f159, %f60;
	cvt.f64.f32 	%fd11, %f160;
	div.rn.f64 	%fd12, %fd11, 0d4079000000000000;
	mul.f64 	%fd13, %fd12, 0d406FE00000000000;
	cvt.rzi.u32.f64 	%r251, %fd13;
	cvt.u16.u32 	%rs1, %r251;
	mul.lo.s32 	%r252, %r74, 3;
	cvt.s64.s32 	%rd85, %r252;
	cvta.to.global.u64 	%rd86, %rd33;
	add.s64 	%rd87, %rd86, %rd85;
	st.global.u8 	[%rd87], %rs1;
	st.global.u8 	[%rd87+1], %rs1;
	st.global.u8 	[%rd87+2], %rs1;

$L__BB0_62:
	ret;

}

