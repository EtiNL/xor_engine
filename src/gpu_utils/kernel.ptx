//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_52
.address_size 64

	// .globl	generate_image

.visible .entry generate_image(
	.param .u32 generate_image_param_0,
	.param .u32 generate_image_param_1,
	.param .u64 generate_image_param_2
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<14>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r3, [generate_image_param_0];
	ld.param.u32 	%r4, [generate_image_param_1];
	ld.param.u64 	%rd1, [generate_image_param_2];
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r6, %r5, %r7;
	mov.u32 	%r8, %ntid.y;
	mov.u32 	%r9, %ctaid.y;
	mov.u32 	%r10, %tid.y;
	mad.lo.s32 	%r2, %r9, %r8, %r10;
	setp.ge.s32 	%p1, %r1, %r3;
	setp.ge.s32 	%p2, %r2, %r4;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_2;

	mad.lo.s32 	%r11, %r2, %r3, %r1;
	mul.lo.s32 	%r12, %r11, 3;
	cvt.s64.s32 	%rd2, %r12;
	cvta.to.global.u64 	%rd3, %rd1;
	add.s64 	%rd4, %rd3, %rd2;
	st.global.u8 	[%rd4], %r1;
	st.global.u8 	[%rd4+1], %r2;
	add.s32 	%r13, %r1, %r2;
	st.global.u8 	[%rd4+2], %r13;

$L__BB0_2:
	ret;

}
	// .globl	draw_circle
.visible .entry draw_circle(
	.param .u32 draw_circle_param_0,
	.param .u32 draw_circle_param_1,
	.param .f32 draw_circle_param_2,
	.param .f32 draw_circle_param_3,
	.param .u64 draw_circle_param_4
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<9>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<5>;


	ld.param.u32 	%r4, [draw_circle_param_0];
	ld.param.u32 	%r5, [draw_circle_param_1];
	ld.param.f32 	%f1, [draw_circle_param_2];
	ld.param.f32 	%f2, [draw_circle_param_3];
	ld.param.u64 	%rd1, [draw_circle_param_4];
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r7, %r6, %r8;
	mov.u32 	%r9, %ntid.y;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %tid.y;
	mad.lo.s32 	%r2, %r10, %r9, %r11;
	setp.ge.s32 	%p1, %r1, %r4;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_3;

	mad.lo.s32 	%r3, %r2, %r4, %r1;
	cvt.rn.f32.s32 	%f3, %r1;
	sub.f32 	%f4, %f3, %f1;
	cvt.rn.f32.s32 	%f5, %r2;
	sub.f32 	%f6, %f5, %f2;
	mul.f32 	%f7, %f6, %f6;
	fma.rn.f32 	%f8, %f4, %f4, %f7;
	setp.gtu.f32 	%p4, %f8, 0f43C80000;
	@%p4 bra 	$L__BB1_3;

	mul.lo.s32 	%r12, %r3, 3;
	cvt.s64.s32 	%rd2, %r12;
	cvta.to.global.u64 	%rd3, %rd1;
	add.s64 	%rd4, %rd3, %rd2;
	mov.u16 	%rs1, 255;
	st.global.u8 	[%rd4], %rs1;
	mov.u16 	%rs2, 0;
	st.global.u8 	[%rd4+1], %rs2;
	st.global.u8 	[%rd4+2], %rs2;

$L__BB1_3:
	ret;

}
	// .globl	produit_scalaire
.visible .entry produit_scalaire(
	.param .u32 produit_scalaire_param_0,
	.param .u64 produit_scalaire_param_1,
	.param .u64 produit_scalaire_param_2,
	.param .u64 produit_scalaire_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<12>;


	ld.param.u32 	%r2, [produit_scalaire_param_0];
	ld.param.u64 	%rd1, [produit_scalaire_param_1];
	ld.param.u64 	%rd2, [produit_scalaire_param_2];
	ld.param.u64 	%rd3, [produit_scalaire_param_3];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB2_2;

	cvta.to.global.u64 	%rd4, %rd3;
	mul.lo.s32 	%r6, %r1, 3;
	cvt.s64.s32 	%rd5, %r6;
	cvta.to.global.u64 	%rd6, %rd1;
	add.s64 	%rd7, %rd6, %rd5;
	ld.global.u8 	%r7, [%rd7];
	cvta.to.global.u64 	%rd8, %rd2;
	add.s64 	%rd9, %rd8, %rd5;
	ld.global.u8 	%r8, [%rd9];
	mul.lo.s32 	%r9, %r8, %r7;
	ld.global.u8 	%r10, [%rd7+1];
	ld.global.u8 	%r11, [%rd9+1];
	mad.lo.s32 	%r12, %r11, %r10, %r9;
	ld.global.u8 	%r13, [%rd7+2];
	ld.global.u8 	%r14, [%rd9+2];
	mad.lo.s32 	%r15, %r14, %r13, %r12;
	cvt.s64.s32 	%rd10, %r1;
	add.s64 	%rd11, %rd4, %rd10;
	st.global.u8 	[%rd11], %r15;

$L__BB2_2:
	ret;

}
	// .globl	sdf_sphere
.visible .entry sdf_sphere(
	.param .u32 sdf_sphere_param_0,
	.param .f32 sdf_sphere_param_1,
	.param .f32 sdf_sphere_param_2,
	.param .f32 sdf_sphere_param_3,
	.param .f32 sdf_sphere_param_4,
	.param .u64 sdf_sphere_param_5,
	.param .u64 sdf_sphere_param_6,
	.param .u64 sdf_sphere_param_7,
	.param .u64 sdf_sphere_param_8
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<16>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<15>;


	ld.param.u32 	%r2, [sdf_sphere_param_0];
	ld.param.f32 	%f1, [sdf_sphere_param_1];
	ld.param.f32 	%f2, [sdf_sphere_param_2];
	ld.param.f32 	%f3, [sdf_sphere_param_3];
	ld.param.f32 	%f4, [sdf_sphere_param_4];
	ld.param.u64 	%rd1, [sdf_sphere_param_5];
	ld.param.u64 	%rd2, [sdf_sphere_param_6];
	ld.param.u64 	%rd3, [sdf_sphere_param_7];
	ld.param.u64 	%rd4, [sdf_sphere_param_8];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB3_2;

	cvta.to.global.u64 	%rd5, %rd3;
	mul.lo.s32 	%r6, %r1, 3;
	cvt.s64.s32 	%rd6, %r6;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	ld.global.u8 	%r7, [%rd8];
	cvt.s64.s32 	%rd9, %r1;
	add.s64 	%rd10, %rd5, %rd9;
	ld.global.u8 	%r8, [%rd10];
	cvta.to.global.u64 	%rd11, %rd2;
	add.s64 	%rd12, %rd11, %rd6;
	ld.global.u8 	%r9, [%rd12];
	mad.lo.s32 	%r10, %r9, %r8, %r7;
	cvt.rn.f32.s32 	%f5, %r10;
	sub.f32 	%f6, %f5, %f1;
	ld.global.u8 	%r11, [%rd8+1];
	ld.global.u8 	%r12, [%rd12+1];
	mad.lo.s32 	%r13, %r12, %r8, %r11;
	cvt.rn.f32.s32 	%f7, %r13;
	sub.f32 	%f8, %f7, %f2;
	ld.global.u8 	%r14, [%rd8+2];
	ld.global.u8 	%r15, [%rd12+2];
	mad.lo.s32 	%r16, %r15, %r8, %r14;
	cvt.rn.f32.s32 	%f9, %r16;
	sub.f32 	%f10, %f9, %f3;
	mul.f32 	%f11, %f8, %f8;
	fma.rn.f32 	%f12, %f6, %f6, %f11;
	fma.rn.f32 	%f13, %f10, %f10, %f12;
	sqrt.rn.f32 	%f14, %f13;
	sub.f32 	%f15, %f14, %f4;
	cvt.rzi.u32.f32 	%r17, %f15;
	cvta.to.global.u64 	%rd13, %rd4;
	add.s64 	%rd14, %rd13, %rd9;
	st.global.u8 	[%rd14], %r17;

$L__BB3_2:
	ret;

}
	// .globl	grad_sdf_sphere
.visible .entry grad_sdf_sphere(
	.param .u32 grad_sdf_sphere_param_0,
	.param .f32 grad_sdf_sphere_param_1,
	.param .f32 grad_sdf_sphere_param_2,
	.param .f32 grad_sdf_sphere_param_3,
	.param .f32 grad_sdf_sphere_param_4,
	.param .u64 grad_sdf_sphere_param_5,
	.param .u64 grad_sdf_sphere_param_6,
	.param .u64 grad_sdf_sphere_param_7,
	.param .u64 grad_sdf_sphere_param_8
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<14>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<15>;


	ld.param.u32 	%r2, [grad_sdf_sphere_param_0];
	ld.param.f32 	%f1, [grad_sdf_sphere_param_1];
	ld.param.f32 	%f2, [grad_sdf_sphere_param_2];
	ld.param.f32 	%f3, [grad_sdf_sphere_param_3];
	ld.param.f32 	%f4, [grad_sdf_sphere_param_4];
	ld.param.u64 	%rd1, [grad_sdf_sphere_param_5];
	ld.param.u64 	%rd2, [grad_sdf_sphere_param_6];
	ld.param.u64 	%rd3, [grad_sdf_sphere_param_7];
	ld.param.u64 	%rd4, [grad_sdf_sphere_param_8];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB4_2;

	cvta.to.global.u64 	%rd5, %rd3;
	mul.lo.s32 	%r6, %r1, 3;
	cvt.s64.s32 	%rd6, %r6;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	ld.global.u8 	%r7, [%rd8];
	cvt.s64.s32 	%rd9, %r1;
	add.s64 	%rd10, %rd5, %rd9;
	ld.global.u8 	%r8, [%rd10];
	cvta.to.global.u64 	%rd11, %rd2;
	add.s64 	%rd12, %rd11, %rd6;
	ld.global.u8 	%r9, [%rd12];
	mad.lo.s32 	%r10, %r9, %r8, %r7;
	cvt.rn.f32.s32 	%f5, %r10;
	sub.f32 	%f6, %f5, %f1;
	div.rn.f32 	%f7, %f6, %f4;
	cvt.rzi.u32.f32 	%r11, %f7;
	cvta.to.global.u64 	%rd13, %rd4;
	add.s64 	%rd14, %rd13, %rd6;
	st.global.u8 	[%rd14], %r11;
	ld.global.u8 	%r12, [%rd8+1];
	ld.global.u8 	%r13, [%rd10];
	ld.global.u8 	%r14, [%rd12+1];
	mad.lo.s32 	%r15, %r14, %r13, %r12;
	cvt.rn.f32.s32 	%f8, %r15;
	sub.f32 	%f9, %f8, %f2;
	div.rn.f32 	%f10, %f9, %f4;
	cvt.rzi.u32.f32 	%r16, %f10;
	st.global.u8 	[%rd14+1], %r16;
	ld.global.u8 	%r17, [%rd8+2];
	ld.global.u8 	%r18, [%rd10];
	ld.global.u8 	%r19, [%rd12+2];
	mad.lo.s32 	%r20, %r19, %r18, %r17;
	cvt.rn.f32.s32 	%f11, %r20;
	sub.f32 	%f12, %f11, %f3;
	div.rn.f32 	%f13, %f12, %f4;
	cvt.rzi.u32.f32 	%r21, %f13;
	st.global.u8 	[%rd14+2], %r21;

$L__BB4_2:
	ret;

}
	// .globl	newton_march
.visible .entry newton_march(
	.param .u32 newton_march_param_0,
	.param .f32 newton_march_param_1,
	.param .u64 newton_march_param_2,
	.param .u64 newton_march_param_3,
	.param .u64 newton_march_param_4,
	.param .u64 newton_march_param_5,
	.param .u64 newton_march_param_6,
	.param .u64 newton_march_param_7
)
{
	.reg .pred 	%p<3>;
	.reg .b16 	%rs<4>;
	.reg .f32 	%f<8>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<17>;


	ld.param.u32 	%r2, [newton_march_param_0];
	ld.param.f32 	%f3, [newton_march_param_1];
	ld.param.u64 	%rd3, [newton_march_param_2];
	ld.param.u64 	%rd4, [newton_march_param_3];
	ld.param.u64 	%rd5, [newton_march_param_5];
	ld.param.u64 	%rd6, [newton_march_param_6];
	ld.param.u64 	%rd7, [newton_march_param_7];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r4, %r3, %r5;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB5_4;

	cvta.to.global.u64 	%rd8, %rd5;
	cvt.s64.s32 	%rd1, %r1;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd1;
	ld.global.u8 	%rs1, [%rd10];
	cvt.rn.f32.u16 	%f4, %rs1;
	cvta.to.global.u64 	%rd11, %rd4;
	add.s64 	%rd12, %rd11, %rd1;
	ld.global.u8 	%rs2, [%rd12];
	cvt.rn.f32.u16 	%f5, %rs2;
	add.s64 	%rd2, %rd8, %rd1;
	ld.global.u8 	%rs3, [%rd2];
	cvt.rn.f32.u16 	%f1, %rs3;
	neg.f32 	%f6, %f5;
	div.rn.f32 	%f2, %f6, %f4;
	setp.gt.f32 	%p2, %f2, %f3;
	@%p2 bra 	$L__BB5_3;
	bra.uni 	$L__BB5_2;

$L__BB5_3:
	add.f32 	%f7, %f2, %f1;
	cvt.rzi.u32.f32 	%r11, %f7;
	st.global.u8 	[%rd2], %r11;
	bra.uni 	$L__BB5_4;

$L__BB5_2:
	cvt.rzi.u32.f32 	%r6, %f1;
	cvta.to.global.u64 	%rd13, %rd6;
	add.s64 	%rd14, %rd13, %rd1;
	st.global.u8 	[%rd14], %r6;
	cvta.to.global.u64 	%rd15, %rd7;
	add.s64 	%rd16, %rd15, %rd1;
	ld.global.u8 	%r7, [%rd16];
	and.b32  	%r8, %r6, 255;
	add.s32 	%r9, %r8, %r7;
	shr.u32 	%r10, %r9, 1;
	st.global.u8 	[%rd2], %r10;

$L__BB5_4:
	ret;

}
	// .globl	camera
.visible .entry camera(
	.param .u32 camera_param_0,
	.param .f32 camera_param_1,
	.param .f32 camera_param_2,
	.param .u64 camera_param_3,
	.param .u64 camera_param_4,
	.param .u64 camera_param_5,
	.param .u64 camera_param_6,
	.param .u64 camera_param_7,
	.param .u64 camera_param_8,
	.param .u64 camera_param_9,
	.param .u64 camera_param_10
)
{



	ret;

}
	// .globl	render
.visible .entry render(
	.param .u32 render_param_0,
	.param .f32 render_param_1,
	.param .f32 render_param_2,
	.param .u64 render_param_3,
	.param .u64 render_param_4,
	.param .u64 render_param_5
)
{
	.reg .pred 	%p<15>;
	.reg .b16 	%rs<26>;
	.reg .f32 	%f<145>;
	.reg .b32 	%r<69>;
	.reg .b64 	%rd<22>;


	ld.param.u32 	%r31, [render_param_0];
	ld.param.f32 	%f54, [render_param_1];
	ld.param.f32 	%f55, [render_param_2];
	ld.param.u64 	%rd10, [render_param_3];
	ld.param.u64 	%rd11, [render_param_4];
	ld.param.u64 	%rd9, [render_param_5];
	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd2, %rd10;
	mov.u32 	%r32, %ntid.x;
	mov.u32 	%r33, %ctaid.x;
	mov.u32 	%r34, %tid.x;
	mad.lo.s32 	%r1, %r33, %r32, %r34;
	mov.u32 	%r35, %ntid.y;
	mov.u32 	%r36, %ctaid.y;
	mov.u32 	%r37, %tid.y;
	mad.lo.s32 	%r2, %r36, %r35, %r37;
	cvt.rn.f32.s32 	%f1, %r1;
	setp.geu.f32 	%p1, %f1, %f54;
	cvt.rn.f32.s32 	%f2, %r2;
	setp.geu.f32 	%p2, %f2, %f55;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB7_21;

	cvt.rzi.s32.f32 	%r39, %f54;
	mad.lo.s32 	%r3, %r39, %r2, %r1;
	setp.lt.s32 	%p4, %r31, 1;
	mov.u32 	%r57, 0;
	mov.f32 	%f115, 0f00000000;
	mov.f32 	%f116, %f115;
	mov.f32 	%f117, %f115;
	@%p4 bra 	$L__BB7_18;

	add.s32 	%r43, %r31, -1;
	and.b32  	%r66, %r31, 3;
	setp.lt.u32 	%p5, %r43, 3;
	mov.f32 	%f117, 0f00000000;
	mov.u32 	%r62, 0;
	mov.u32 	%r57, %r62;
	mov.f32 	%f116, %f117;
	mov.f32 	%f115, %f117;
	@%p5 bra 	$L__BB7_13;

	sub.s32 	%r56, %r31, %r66;

$L__BB7_4:
	shl.b32 	%r46, %r62, 1;
	cvt.s64.s32 	%rd12, %r46;
	add.s64 	%rd3, %rd2, %rd12;
	ld.global.u8 	%rs1, [%rd3];
	cvt.rn.f32.u16 	%f66, %rs1;
	ld.global.u8 	%rs2, [%rd3+1];
	cvt.rn.f32.u16 	%f67, %rs2;
	sub.f32 	%f68, %f66, %f1;
	sub.f32 	%f69, %f67, %f2;
	mul.f32 	%f70, %f69, %f69;
	fma.rn.f32 	%f71, %f68, %f68, %f70;
	setp.gtu.f32 	%p6, %f71, 0f3F800000;
	mul.lo.s32 	%r47, %r62, 3;
	cvt.s64.s32 	%rd13, %r47;
	add.s64 	%rd4, %rd1, %rd13;
	@%p6 bra 	$L__BB7_6;

	ld.global.u8 	%rs3, [%rd4];
	cvt.rn.f32.u16 	%f72, %rs3;
	add.f32 	%f115, %f115, %f72;
	ld.global.u8 	%rs4, [%rd4+1];
	cvt.rn.f32.u16 	%f73, %rs4;
	add.f32 	%f116, %f116, %f73;
	ld.global.u8 	%rs5, [%rd4+2];
	cvt.rn.f32.u16 	%f74, %rs5;
	add.f32 	%f117, %f117, %f74;
	add.s32 	%r57, %r57, 1;

$L__BB7_6:
	ld.global.u8 	%rs6, [%rd3+2];
	cvt.rn.f32.u16 	%f75, %rs6;
	ld.global.u8 	%rs7, [%rd3+3];
	cvt.rn.f32.u16 	%f76, %rs7;
	sub.f32 	%f77, %f75, %f1;
	sub.f32 	%f78, %f76, %f2;
	mul.f32 	%f79, %f78, %f78;
	fma.rn.f32 	%f80, %f77, %f77, %f79;
	setp.gtu.f32 	%p7, %f80, 0f3F800000;
	@%p7 bra 	$L__BB7_8;

	ld.global.u8 	%rs8, [%rd4+3];
	cvt.rn.f32.u16 	%f81, %rs8;
	add.f32 	%f115, %f115, %f81;
	ld.global.u8 	%rs9, [%rd4+4];
	cvt.rn.f32.u16 	%f82, %rs9;
	add.f32 	%f116, %f116, %f82;
	ld.global.u8 	%rs10, [%rd4+5];
	cvt.rn.f32.u16 	%f83, %rs10;
	add.f32 	%f117, %f117, %f83;
	add.s32 	%r57, %r57, 1;

$L__BB7_8:
	ld.global.u8 	%rs11, [%rd3+4];
	cvt.rn.f32.u16 	%f84, %rs11;
	ld.global.u8 	%rs12, [%rd3+5];
	cvt.rn.f32.u16 	%f85, %rs12;
	sub.f32 	%f86, %f84, %f1;
	sub.f32 	%f87, %f85, %f2;
	mul.f32 	%f88, %f87, %f87;
	fma.rn.f32 	%f89, %f86, %f86, %f88;
	setp.gtu.f32 	%p8, %f89, 0f3F800000;
	@%p8 bra 	$L__BB7_10;

	ld.global.u8 	%rs13, [%rd4+6];
	cvt.rn.f32.u16 	%f90, %rs13;
	add.f32 	%f115, %f115, %f90;
	ld.global.u8 	%rs14, [%rd4+7];
	cvt.rn.f32.u16 	%f91, %rs14;
	add.f32 	%f116, %f116, %f91;
	ld.global.u8 	%rs15, [%rd4+8];
	cvt.rn.f32.u16 	%f92, %rs15;
	add.f32 	%f117, %f117, %f92;
	add.s32 	%r57, %r57, 1;

$L__BB7_10:
	ld.global.u8 	%rs16, [%rd3+6];
	cvt.rn.f32.u16 	%f93, %rs16;
	ld.global.u8 	%rs17, [%rd3+7];
	cvt.rn.f32.u16 	%f94, %rs17;
	sub.f32 	%f95, %f93, %f1;
	sub.f32 	%f96, %f94, %f2;
	mul.f32 	%f97, %f96, %f96;
	fma.rn.f32 	%f98, %f95, %f95, %f97;
	setp.gtu.f32 	%p9, %f98, 0f3F800000;
	@%p9 bra 	$L__BB7_12;

	ld.global.u8 	%rs18, [%rd4+9];
	cvt.rn.f32.u16 	%f99, %rs18;
	add.f32 	%f115, %f115, %f99;
	ld.global.u8 	%rs19, [%rd4+10];
	cvt.rn.f32.u16 	%f100, %rs19;
	add.f32 	%f116, %f116, %f100;
	ld.global.u8 	%rs20, [%rd4+11];
	cvt.rn.f32.u16 	%f101, %rs20;
	add.f32 	%f117, %f117, %f101;
	add.s32 	%r57, %r57, 1;

$L__BB7_12:
	add.s32 	%r62, %r62, 4;
	add.s32 	%r56, %r56, -4;
	setp.ne.s32 	%p10, %r56, 0;
	@%p10 bra 	$L__BB7_4;

$L__BB7_13:
	setp.eq.s32 	%p11, %r66, 0;
	@%p11 bra 	$L__BB7_18;

	mad.lo.s32 	%r64, %r62, 3, 1;
	shl.b32 	%r48, %r62, 1;
	cvt.s64.s32 	%rd14, %r48;
	add.s64 	%rd15, %rd2, %rd14;
	add.s64 	%rd21, %rd15, 1;

$L__BB7_15:
	.pragma "nounroll";
	ld.global.u8 	%rs21, [%rd21+-1];
	cvt.rn.f32.u16 	%f102, %rs21;
	ld.global.u8 	%rs22, [%rd21];
	cvt.rn.f32.u16 	%f103, %rs22;
	sub.f32 	%f104, %f102, %f1;
	sub.f32 	%f105, %f103, %f2;
	mul.f32 	%f106, %f105, %f105;
	fma.rn.f32 	%f107, %f104, %f104, %f106;
	setp.gtu.f32 	%p12, %f107, 0f3F800000;
	@%p12 bra 	$L__BB7_17;

	add.s32 	%r49, %r64, -1;
	cvt.s64.s32 	%rd16, %r49;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.u8 	%rs23, [%rd17];
	cvt.rn.f32.u16 	%f108, %rs23;
	add.f32 	%f115, %f115, %f108;
	ld.global.u8 	%rs24, [%rd17+1];
	cvt.rn.f32.u16 	%f109, %rs24;
	add.f32 	%f116, %f116, %f109;
	ld.global.u8 	%rs25, [%rd17+2];
	cvt.rn.f32.u16 	%f110, %rs25;
	add.f32 	%f117, %f117, %f110;
	add.s32 	%r57, %r57, 1;

$L__BB7_17:
	add.s32 	%r64, %r64, 3;
	add.s64 	%rd21, %rd21, 2;
	add.s32 	%r66, %r66, -1;
	setp.ne.s32 	%p13, %r66, 0;
	@%p13 bra 	$L__BB7_15;

$L__BB7_18:
	setp.lt.s32 	%p14, %r57, 1;
	@%p14 bra 	$L__BB7_20;

	cvt.rn.f32.s32 	%f111, %r57;
	div.rn.f32 	%f115, %f115, %f111;
	div.rn.f32 	%f116, %f116, %f111;
	div.rn.f32 	%f117, %f117, %f111;

$L__BB7_20:
	cvt.rzi.u32.f32 	%r50, %f115;
	mul.lo.s32 	%r51, %r3, 3;
	cvt.s64.s32 	%rd18, %r51;
	cvta.to.global.u64 	%rd19, %rd9;
	add.s64 	%rd20, %rd19, %rd18;
	st.global.u8 	[%rd20], %r50;
	cvt.rzi.u32.f32 	%r52, %f116;
	st.global.u8 	[%rd20+1], %r52;
	cvt.rzi.u32.f32 	%r53, %f117;
	st.global.u8 	[%rd20+2], %r53;

$L__BB7_21:
	ret;

}

